model:
  variance_threshold: 0.02
  f_test_method: spearmanr
  f_test_threshold: 0.15
  target: fpl_points
  baseline_columns: [fpl_points_ma5]
  not_features:
    - id
    - fpl_name
    - date
    - player
  categorical_features:
    - team
    - opponent
    - venue
    - pos
  numerical_features:
    - round
    - value
    - att_total
    - home_att_total
    - away_att_total
    - def_total
    - home_def_total
    - away_def_total
    - pts_b4_match
    - rank_b4_match
    - pts_gap_above
    - pts_gap_below
    - min_ma5
    - gls_ma5
    - ast_ma5
    - pk_ma5
    - pkatt_ma5
    - sh_ma5
    - sot_ma5
    - touches_ma5
    - xg_ma5
    - npxg_ma5
    - xag_ma5
    - sca_ma5
    - gca_ma5
    - sota_ma5
    - ga_ma5
    - saves_ma5
    - savepct_ma5
    - cs_ma5
    - psxg_ma5
    - team_poss_ma5
    - team_gf_ma5
    - team_ga_ma5
    - team_xg_ma5
    - team_xga_ma5
    - fpl_points_ma5
    - value_ma5
    - att_elo_ma5
    - def_elo_ma5
    - home_att_elo_ma5
    - home_def_elo_ma5
    - away_att_elo_ma5
    - away_def_elo_ma5
    - att_elo_opp_ma5
    - def_elo_opp_ma5
    - home_att_elo_opp_ma5
    - home_def_elo_opp_ma5
    - away_att_elo_opp_ma5
    - away_def_elo_opp_ma5
    - att_total_ma5
    - home_att_total_ma5
    - away_att_total_ma5
    - def_total_ma5
    - home_def_total_ma5
    - away_def_total_ma5
    - match_points_ma5
    - league_points_ma5
  group_by: season
  pca_components: 7
  random_state: 42
  verbose: false
  n_jobs: null
  sort_models: r2
  models:
    - ridge
    - lr
    - lightgbm
    - gbr
    - huber
  model_weights: [1, 1, 1, 1, 1]

  ridge_params:
    alpha: 9.99

  lr_params:
    fit_intercept: True

  lightgbm_params:
    num_leaves: 31
    learning_rate: 0.1
    n_estimators: 100
    min_split_gain: 0.0
    reg_alpha: 0.0
    reg_lambda: 0.0
    feature_fraction: 1.0
    bagging_fraction: 1.0
    bagging_freq: 0
    min_child_samples: 20

  gbr_params:
    n_estimators: 233
    learning_rate: 0.068
    subsample: 0.88
    min_samples_split: 7
    max_depth: 1
    max_features: 0.63
    min_impurity_decrease: 0.011
    n_iter_no_change: null

  huber_params:
    epsilon: 1.35
    alpha: 0.0001
    fit_intercept: True

hyperopt:
  target:
    name: val_score
    max_trials: 50
    strategy: max
    algo: tpe
    early_termination: null
  groups:
    model:
      models:
        # - [lr]
        - [ridge]
        - [huber]
        # - [lightgbm]
        # - [gbr]
  # 0:
  #   model:
  #     lr_params:
  #       fit_intercept:
  #         method: choice
  #         values: [True, False]
  0:
    model:
      ridge_params:
        alpha:
          method: uniform
          low: 0.001
          high: 10
        fit_intercept:
          method: choice
          values: [True, False]
  1:
    model:
      huber_params:
        epsilon:
          method: uniform
          low: 1
          high: 2
        alpha:
          method: uniform
          low: 0.0000000001
          high: 0.9999999999
        fit_intercept:
          method: choice
          values: [True, False]
  # 2:
  #   model:
  #     lightgbm_params:
  #       num_leaves:
  #         method: uniform
  #         scope: int
  #         low: 2
  #         high: 256
  #       learning_rate:
  #         method: loguniform
  #         low: 0.000001
  #         high: 0.5
  #       n_estimators:
  #         method: uniform
  #         scope: int
  #         low: 10
  #         high: 300
  #       min_split_gain:
  #         method: uniform
  #         low: 0
  #         high: 1
  #       reg_alpha:
  #         method: loguniform
  #         low: 0.0000000001
  #         high: 10
  #       reg_lambda:
  #         method: loguniform
  #         low: 0.0000000001
  #         high: 10
  #       feature_fraction:
  #         method: uniform
  #         low: 0.4
  #         high: 1
  #       bagging_fraction:
  #         method: uniform
  #         low: 0.4
  #         high: 1
  #       bagging_freq:
  #         method: uniform
  #         scope: int
  #         low: 0
  #         high: 7
  #       min_child_samples:
  #         method: uniform
  #         scope: int
  #         low: 1
  #         high: 100
  # 3:
  #   model:
  #     gbr_params:
  #       n_estimators:
  #         method: uniform
  #         scope: int
  #         low: 10
  #         high: 300
  #       learning_rate:
  #         method: loguniform
  #         low: -6
  #         high: -0.69
  #       subsample:
  #         method: uniform
  #         low: 0.2
  #         high: 1
  #       min_samples_split:
  #         method: uniform
  #         scope: int
  #         low: 2
  #         high: 10
  #       min_samples_leaf:
  #         method: uniform
  #         scope: int
  #         low: 1
  #         high: 5
  #       max_depth:
  #         method: uniform
  #         scope: int
  #         low: 1
  #         high: 11
  #       max_features:
  #         method: uniform
  #         low: 0.4
  #         high: 1
  #       min_impurity_decrease:
  #         method: loguniform
  #         low: -9
  #         high: -0.69

######################################

data:
  elo_learning_rate: 0.1
  home_away_weight: 0.5
  start_year: 2016-2017
  holdout_year: 2022-2023
  ma_lag: 5
  debug_run: False
  use_cache: False

######################################

housekeeping:
  to_keep: 30
  keep_model_best: 3
  metric: val_r2
  strategy: max

######################################

optimization:
  team_id: 3531385
  ft: 1
  horizon: 3
  tr_horizon: 2
  wc_on: 8
  bb_on: null
  fh_on: null
  timeout: 60
  log: false
  decay: 0.5
  ft_bonus: 1.5
  itb_bonus: 0.08
  bench_weights: { 0: 0.03, 1: 0.21, 2: 0.06, 3: 0.002 }
  solver: cplex
  backtest_player_history: true
  backtest_players:
    Me: 3531385
    Hazard: 1195527
    FPL Raptor: 5431
    Donald: 307190

######################################

scraper:
  current_season: 2023-2024
  fresh_start: False
  headless: True
